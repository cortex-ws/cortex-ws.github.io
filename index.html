<!DOCTYPE HTML>
<!-- Website template by freewebsitetemplates.com -->
<html>
<head>
	<meta charset="UTF-8">
	<title>The First International Workshop  COmputing using EmeRging  EXotic AI-Inspired Systems (CORtEX'22)</title>
	<link rel="stylesheet" href="css/style.css" type="text/css">
</head>
<body>
	<div id="header">
		<div>
			<div class="logo">
				<a href="index.html"></a>
			</div>
			<ul id="navigation">
				<li class="active">
					<a href="index.html">Top</a>
				</li>
				<li>
					<a href="#program">Workshop Program</a>
				</li>
				<li>
					<a href="#dates">Important Dates</a>
				</li>
				<li>
					<a href="#papsubmission">Paper submission</a>
				</li>
				<li>
					<a href="#organization">Organization</a>
				</li>
			</ul>
		</div>
	</div>



	<div id="contents">
<h1>The First International Workshop  COmputing using EmeRging  EXotic AI-Inspired Sysems (CORtEX'22)</h1>
			<p>The field of artificial intelligence (AI) has experienced fantastic technological advancement in the past decade. Today, AI is permeating practically every layer of science and society. Much of the AI technology and theory has been inspired by discoveries made decades ago in neuroscience. For example, the artificial neuron is an abstraction of single-point neurons in computational neuroscience, the (well-known) convolution neural networks are based on research performed on cat visual cortex in the 1970s etc. </p>

<p> Deep Learning (DL), the dominant methodology of modern AI enjoyed particular success due (in part) to the advances in highly parallel computing system and their performance characteristics well matching those of DL workloads. But some AI researchers are looking beyond current Deep Learning methods to address the limitations in tasks like abstract reasoning. </p>

<p> At the same time, there was also a remarkable progress in deepening our understanding of how the human brain works, inspiring novel methods of computational intelligence. For example, the discovery of Spike Timing Dependent Plasticity (STDP), which is a local learning rule for the training of brain-inspired neurons, is facilitating Deep-Learning-like performance in certain tasks and is currently being extended to support multiple-factor learning to facilitate (for example) learn-to-learn (self-learning). Another example is the Bayesian Confidence Propagation Neural Network (BCPNN), whose theory dates back to the 1990s but today is showing great potential as an un-/semi-supervised method for learning while at the same time carrying more biological meaning than traditional AI methods.</p>

<p> Finally, with the end of Moore's law, the computing industry is actively looking for alternative ways to perform computation. Many of these emerging ways to compute are to focus exclusively on supporting the functionality that neuroscience and AI require. For example, by mimicking how the brain computes, computer scientists are building neuromorphic systems (in essence, brain-on-chips) that are fast and extremely power-efficient (orders of magnitude less than a CPU for the same task), and could help solve some of the largest challenge in neuroscience today. Examples of neuromorphic chips are Intel Loihi or IBM TrueNorth.</p>

<p> The emergence of new (beyond DL) challenges in AI, the increase in maturity of computational neuroscience, the end of Moore's law, and the emergence of novel neuromorphic systems are not a coincidence. Instead, they are an opportunity for these  fields to come together and work on solving common, computational demanding tasks and draw inspiration and knowledge from each other.</p>

<p> Unfortunately, a majority of existing workshops are occlusive and specialized, and there is today no open forum that crosses these disciplines (HPC, neuroscience, hardware, software) to encourage knowledge transfer and discussions. This workshop aspires to fill this void.</p>

<p> The First International Workshop \textbf{CO}mputing using EmeRging EXotic AI-Inspired Systems (CORTEX'22) aspires to provide a recurring and open international forum for discussing, disseminating, technology transfer, and opening up collaboration across the HPC, the neuroscience, the software, and the hardware communities with respect to crosscutting bio-inspired methods in artificial intelligence and other emerging AI paradigms. The driving force behind the workshop is its interdisciplinary nature, allowing the workshop to focus on subjects that span the boundaries of several disciplines.</p>



			<h1 id="program">Tentative Program</h1>

			<ul>
			    <h3>09:00-09:15: Opening </h3>
				
			    <h3>09:15-10:00: Keynote #1 </h3>

			    <h3>10:00-12:00: Paper session</h3>

			    <h3>13:15-14:00: Keynote #2 </h3>
			    
			    <h3>14:15-15:00: Poster/Lightning Talks</h3>
			    
			    <h3>15:15-17:00: Panel and Open forum discussion</h3>
			    
			    <h3>17:00-17:15: Concluding remarks</h3>
			</ul>



			<h1 id="dates">Important Dates</h1>
				<p> Paper submission: January 26th, 2022<br>
				    Paper notification: March 10th, 2022<br>
				    Camera ready due: TBD<br>
				    Workshop date: TBD</p>

			<h1 id="papsubmission">Topics of Interest and Paper submission</h1>
<p> Authors will be invited to submit preliminary work as either regular papers (up-to 8 pages) or poster presentations (2 pages) for presentation at the conference. The submitted work shall be in the English language, not be under consideration elsewhere, and will be peer-reviewed by the technical program committee (TPC).  Topics of interest for workshop submissions include (but are not limited to): 
</p>

			<h2> Topics of interests </h2>
			<ul>
			    <li>Computational neuroscience theory and case-studies on artificial intelligence</li>
			    <li>Software systems for neuromorphic computing, including benchmarks and case-studies</li>
			    <li>Hardware systems for neuromorphic computing, including hardware accelerators, reconfigurable systems (e.g., FPGAs), or the use of emerging non-CMOS technologies</li>
			    <li>Frameworks for neuromorphic computing through domain-specific languages or libraries (e.g., Nengo)</li>
			    <li>Emerging brain-inspired artificial intelligence abstractions, algorithms, implementations, or case-studies (e.g., Hierarchical Temporal Memory, BCPNN)</li>
			    <li>Studies that compares and position the use of neuromorphic hardware compared to general-purpose systems (CPUs or GPUs) for various use-cases</li>
			</ul>

			<p> <br> Click <a href="index.html">HERE</a> to come to the EasyChair submission page. </p>


			<h1 id="organization">Organization</h1>
			<h2>CORTEX'22 Organizers</h2>
			<ul>
				<li>Artur Podobas (KTH Royal Institute of Technology, Sweden)</li>
				<li>Aleksandr Drozd (RIKEN Center for Computational Science, Japan)</li>
				<li>Catherine Schuman (Oak Ridge National Laboratory, USA)</li>
				<li> Barry Devereux (Queen's University Belfast, UK)</li>
			</ul>

			<h2>CORTEX'22 Program Committee</h2>
			<ul>
				<li>Prasanna A Date (Oak Ridge National Laboratory, USA)</li>
				<li>Shruti Kulkarni (Oak Ridge National Laboratory, USA)</li>
				<li>Ekaterina Vylomova (University of Melbourne, Australia)</li>
				<li>Pawel Herman (KTH Royal Institute of Technology, Sweden)</li>
				<li>Stefano Markidis (KTH Royal Institute of Technology, Sweden)</li>
				<li>Jun Igarashi (RIKEN Center for Computation Science, Japan)</li>
				<li>Oliver Rhodes (Univ. of Manchester, United Kingdom)</li>
				<li>Mohammed Wahib (AIST, Japan)</li>
				<li>Raphael Shu (Amazon.com LLC, USA) </li>
				<li>Machel Reid (University of Tokyo, Japan) </li>
				<li>Martin Biehl (Araya Inc., Japan) </li>
				<li>Kaushalya Madhawa (Lily MedTech Inc., Japan) </li>
				

			</ul>


	</div>

</body>
</html>
